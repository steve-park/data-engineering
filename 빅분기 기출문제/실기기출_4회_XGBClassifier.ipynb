{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 데이터 파일 준비\n",
        "# 그냥 실행해서 사용 파일을 생성하도록 합니다.\n",
        "import pandas as pd\n",
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/Soyoung-Yoon/bigdata/main/train_04.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/Soyoung-Yoon/bigdata/main/test_04.csv')\n",
        "train.head(2)\n",
        "X_train = train.iloc[:, :-1]\n",
        "Y_train = train[['ID', 'Segmentation']]\n",
        "X_train.to_csv('X_train.csv', index=False)\n",
        "Y_train.to_csv('Y_train.csv', index=False)\n",
        "test.to_csv('X_test.csv', index=False)\n",
        "print('파일을 준비했습니다!  X_train.csv, Y_train.csv, X_test.csv !')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUAUeca0CHr3",
        "outputId": "8b28db3f-21c3-4aaf-8fd3-58b58e439819"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일을 준비했습니다!  X_train.csv, Y_train.csv, X_test.csv !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zFCq2IcCFdd",
        "outputId": "34fa9e17-da68-4329-c44a-eaf6a895f947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACC : 0.6125 0.5394 F1 : 0.5281 AUC : 0.7919\n"
          ]
        }
      ],
      "source": [
        "# [0] 사용 라이브러리 import\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier  # 마지막주에 정리하고 사용하실 분만 하세요.\n",
        "from lightgbm import LGBMClassifier  # 마지막주에 정리하고 사용하실 분만 하세요.\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
        "\n",
        "def get_scores(model, x_train, x_test, y_train, y_test):\n",
        "    A = model.score(x_train, y_train)  # Accuracy \n",
        "    B = model.score(x_test, y_test)\n",
        "    # A == B (적절), A >> B (과대적합), A, B값이 낮은 값 (과소적합)\n",
        "    y_pred = model.predict(x_test)\n",
        "    C = f1_score(y_test, y_pred, average='macro')  #  f1_score(정답, 예측)\n",
        "    y_proba = model.predict_proba(x_test)\n",
        "    D = roc_auc_score(y_test, y_proba, average='macro', multi_class='ovo')  # multi_class must be in ('ovo', 'ovr')\n",
        "    # precision_score, recall_score # -> f1_score와 사용방법 동일\n",
        "    return f'ACC : {A:.4f} {B:.4f} F1 : {C:.4f} AUC : {D:.4f}'\n",
        "\n",
        "# [1] 파일 읽어오기\n",
        "X = pd.read_csv('X_train.csv')\n",
        "Y = pd.read_csv('Y_train.csv')\n",
        "X_submission = pd.read_csv('X_test.csv')\n",
        "#print(X.shape, Y.shape, X_submission.shape)  # (2154, 1)\n",
        "\n",
        "# [3] X, X_submission을 연결\n",
        "# - 행 삭제, 삽입, 이동이 있으면 안됨\n",
        "# - 열(컬럼)에 대해 제약은 없음 (삭제, 삽입, 이동)\n",
        "dfX = pd.concat([X, X_submission], axis=0)\n",
        "#dfX.nunique()\n",
        "\n",
        "# [3-1] Label Encoding\n",
        "dfX['Gender'] = dfX['Gender'].astype('category').cat.codes\n",
        "dfX['Ever_Married'] = dfX['Ever_Married'].astype('category').cat.codes\n",
        "dfX['Graduated'] = dfX['Graduated'].astype('category').cat.codes\n",
        "# [3-2] OneHot Encoding\n",
        "dfX = pd.get_dummies(dfX)\n",
        "#dfX.info()\n",
        "\n",
        "# [4] 변수선택\n",
        "dfX = dfX.drop(columns=['ID'])\n",
        "\n",
        "# [5] 스케일링 (선택)\n",
        "# 스케일링 결과는 ndarray 이기 때문에 사용시 ndarray의 특징, 사용법을 알고 있어야 함\n",
        "# ndarray를 DataFrame으로 변경해서 사용하자!\n",
        "dfX = pd.DataFrame(MinMaxScaler().fit_transform(dfX), columns=dfX.columns)\n",
        "#print(type(dfX))  # <class 'numpy.ndarray'> // <class 'pandas.core.frame.DataFrame'>\n",
        "\n",
        "# [6] dfX -> X, X_submission 분리\n",
        "X_use = dfX.iloc[:6665, :]          # 모델링, 모델평가\n",
        "X_submission = dfX.iloc[6665:, :]   # 제출용\n",
        "Y_use = Y['Segmentation']\n",
        "Y_use = Y_use - 1   # XGBClassifier\n",
        "#print(Y_use.value_counts(normalize=True))\n",
        "\n",
        "# [7] train, test 분리\n",
        "temp = train_test_split(X_use, Y_use, test_size=0.2, random_state=4321, stratify=Y_use)\n",
        "x_train, x_test, y_train, y_test = temp\n",
        "#print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)\n",
        "#print(X_submission.shape)\n",
        "\n",
        "# [8] 모델선택, 학습, 평가\n",
        "\n",
        "#model1 = LogisticRegression(max_iter=1000)\n",
        "#model1.fit(x_train, y_train)\n",
        "#print(get_scores(model1, x_train, x_test, y_train, y_test))\n",
        "# ACC : 0.5259 0.5244 F1 : 0.5096 AUC : 0.7653\n",
        "\n",
        "#model2 = KNeighborsClassifier(12)\n",
        "#model2.fit(x_train, y_train)\n",
        "#print(get_scores(model2, x_train, x_test, y_train, y_test))\n",
        "\n",
        "#model3 = DecisionTreeClassifier(max_depth=6, random_state=1)\n",
        "#model3.fit(x_train, y_train)\n",
        "#print(model3.get_depth())\n",
        "#print(get_scores(model3, x_train, x_test, y_train, y_test))\n",
        "\n",
        "#model4 = RandomForestClassifier(n_estimators=300, max_depth=6, random_state=1)\n",
        "#model4.fit(x_train, y_train)\n",
        "#print(get_scores(model4, x_train, x_test, y_train, y_test))\n",
        "\n",
        "# XGBClassifier는  [1, 2, 3, 4], [-1, 1] 사용하지 못함\n",
        "# [0, 1, 2, 3], [0, 1]와 같이 수정해 주어야 함\n",
        "# 제출할 때는 [1, 2, 3, 4], [-1, 1] 로 복원해야 함\n",
        "model5 = XGBClassifier(n_estimators=100, max_depth=3, random_state=123) \n",
        "model5.fit(x_train, y_train)\n",
        "print(get_scores(model5, x_train, x_test, y_train, y_test))\n",
        "#ValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3], got [1 2 3 4]\n",
        "#ACC : 0.6303 0.5439 F1 : 0.5331 AUC : 0.7855   n_estimators=50, max_depth=4\n",
        "\n",
        "#model6 = LGBMClassifier(n_estimators=30, max_depth=3, random_state=123)   \n",
        "#model6.fit(x_train, y_train)\n",
        "#print(get_scores(model6, x_train, x_test, y_train, y_test))\n",
        "# ACC : 0.5497 0.5439 F1 : 0.5330 AUC : 0.7916\n",
        "\n",
        "# [9] 제출 파일 작성\n",
        "submission = pd.DataFrame()\n",
        "#submission['Segmentation'] = model6.predict(X_submission)\n",
        "submission['Segmentation'] = model5.predict(X_submission) + 1  # Y_use = Y_use - 1 때문에\n",
        "submission.to_csv('수험번호.csv', index=False)\n",
        "\n",
        "# [10] 제출확인\n",
        "#temp = pd.read_csv('수험번호.csv')\n",
        "#print(temp.shape)\n",
        "#print(temp['Segmentation'].unique())\n",
        "#print(temp.head(5))"
      ]
    }
  ]
}